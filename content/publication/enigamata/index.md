---
abstract: 'It is imperative for Large language models (LLMs) to follow instructions with elaborate requirements (i.e. Complex Instructions Following). Yet, it remains under-explored how to enhance the ability of LLMs to follow complex instructions with multiple constraints. To bridge the gap, we initially study what training data is effective in enhancing complex constraints following abilities. We found that training LLMs with instructions containing multiple constraints enhances their understanding of complex instructions, especially those with lower complexity levels. The improvement can even generalize to compositions of out-of-domain constraints. Additionally, we further propose methods addressing how to obtain and utilize the effective training data. Finally, we conduct extensive experiments to prove the effectiveness of our methods in terms of overall performance, training efficiency, and generalization abilities under four settings.'
slides: ""
url_pdf: 'https://arxiv.org/abs/2505.19914'
publication_types:
    - 'Preprint'
authors:
    - 'Jiangjie Chen'
    - admin
    - 'Siyu Yuan'
    - 'Aili Chen'
    - 'Zhicheng Cai'
    - 'Weinan Dai'
    - 'Hongli Yu'
    - 'Qiying Yu'
    - 'Xuefeng Li'
    - 'Jiaze Chen'
    - 'Hao Zhou'
    - 'Mingxuan Wang'
author_notes: 
  - 'Equal contribution'
  - 'Equal contribution'
  - 'Equal contribution'
  - 'Equal contribution'
publication: Preprint
summary: ""
url_dataset: ""
url_project: ""
publication_short: ""
url_source: ""
url_video: ""
title: 'Enigmata: Scaling Logical Reasoning in Large Language Models with Synthetic Verifiable Puzzles'
doi: ""
featured: true
tags: []
projects: []
image:
    caption: ""
    focal_point: ""
    preview_only: false
    filename: enigmata.png
date: '2025-05-26T02:34:00.000Z'
url_slides: ""
publishDate: '2024-05-26T00:00:00.000Z'
url_poster: ""
url_code: 'https://seed-enigmata.github.io/'
---
